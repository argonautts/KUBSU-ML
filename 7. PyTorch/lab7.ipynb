{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Лабораторная работа №7 PyTorch\n",
    "Группа 45/2\n",
    "---"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Импорт библиотек**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-21T07:23:54.205407Z",
     "start_time": "2023-11-21T07:23:54.184741Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Задание 1.**\n",
    "Загрузить набор данных MNIST, который включает в себя рукописные цифры от 0 до 9."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [],
   "source": [
    "# Определяю преобразования данных, которые будут применены к изображениям MNIST\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # Преобразование изображения в тензор\n",
    "    transforms.Normalize((0.5,), (0.5,))  # Нормализация значений пикселей к диапазону [-1, 1]\n",
    "])\n",
    "\n",
    "# Загрузка набор данных MNIST\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "# Создаю DataLoader для обучающего и тестового наборов данных\n",
    "batch_size = 64\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-21T07:23:54.247425Z",
     "start_time": "2023-11-21T07:23:54.195775Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Задание 2.**\n",
    "Предобработать данные, чтобы они были приведены к нужному формату и масштабу."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,)),\n",
    "    #transforms.Flatten()  # Разглаживание изображений\n",
    "    transforms.Resize((500, 500))  # Изменение размера изображений\n",
    "])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-21T07:23:54.252478Z",
     "start_time": "2023-11-21T07:23:54.249659Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Задание 3.**\n",
    "Создать модель нейронной сети с использованием PyTorch. Модель должна содержать несколько слоев, включая скрытые слои."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.fc1 = nn.Linear(28 * 28, 256)  # Полносвязный слой с 784 входами и 256 выходами\n",
    "        self.fc2 = nn.Linear(256, 128)  # Полносвязный слой с 256 входами и 128 выходами\n",
    "        self.fc3 = nn.Linear(128, 10)  # Полносвязный слой с 128 входами и 10 выходами (для 10 классов)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28 * 28)  # Разглаживание входных данных (приведение в одномерный вектор)\n",
    "        x = F.relu(self.fc1(x))  # Применение функции активации ReLU к первому слою\n",
    "        x = F.relu(self.fc2(x))  # Применение функции активации ReLU ко второму слою\n",
    "        x = self.fc3(x)  # Выходной слой без функции активации (например, для использования CrossEntropyLoss)\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-21T07:23:54.256839Z",
     "start_time": "2023-11-21T07:23:54.253587Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "- nn.Linear(in_features, out_features) - полносвязный слой, где in_features - количество входов, out_features - количество выходов.\n",
    "- F.relu() - функция активации ReLU.\n",
    "- view(-1, 28 * 28) - разглаживание входных данных в одномерный вектор."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Задание 4.**\n",
    "Обучить модель на тренировочном наборе данных, используя функцию потерь и оптимизатор из PyTorch."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 0.4748479425907135\n",
      "Epoch [2/10], Loss: 0.2909955084323883\n",
      "Epoch [3/10], Loss: 0.32635822892189026\n",
      "Epoch [4/10], Loss: 0.186576709151268\n",
      "Epoch [5/10], Loss: 0.054498091340065\n",
      "Epoch [6/10], Loss: 0.11743377149105072\n",
      "Epoch [7/10], Loss: 0.43036291003227234\n",
      "Epoch [8/10], Loss: 0.2416214644908905\n",
      "Epoch [9/10], Loss: 0.18230295181274414\n",
      "Epoch [10/10], Loss: 0.026439432054758072\n"
     ]
    }
   ],
   "source": [
    "# Создание экземпляра модели\n",
    "model = NeuralNetwork()\n",
    "\n",
    "# Определение функции потерь\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Определение оптимизатора (например, стохастический градиентный спуск)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "# Цикл обучения\n",
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for images, labels in train_loader:\n",
    "        # Обнуление градиентов\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Прямой проход\n",
    "        outputs = model(images)\n",
    "        \n",
    "        # Вычисление функции потерь\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Обратное распространение\n",
    "        loss.backward()\n",
    "        \n",
    "        # Обновление весов\n",
    "        optimizer.step()\n",
    "\n",
    "    # Вывод информации о процессе обучения (например, потери на эпохе)\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item()}')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-21T07:24:28.915794Z",
     "start_time": "2023-11-21T07:23:54.259570Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Задание 5.**\n",
    "Оценить качество модели на тестовом наборе данных."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the test set: 94.94%\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = correct / total\n",
    "print(f'Accuracy on the test set: {accuracy * 100:.2f}%')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-21T07:24:29.425160Z",
     "start_time": "2023-11-21T07:24:28.913830Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Код считает точность модели на тестовом наборе данных. Он использует torch.no_grad(), чтобы предотвратить вычисление градиентов при прямом проходе через модель, поскольку в данном контексте нам не нужно обновлять веса."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Задание 6.**\n",
    "Изменить параметры модели (например, число скрытых слоев, количество нейронов в слоях) и сравнить их влияние на качество распознавания."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "outputs": [],
   "source": [
    "# Определение первой модели с ReLU\n",
    "class ModelReLU(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ModelReLU, self).__init__()\n",
    "        self.fc1 = nn.Linear(28 * 28, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28 * 28)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# Определение второй модели с сигмоидальной функцией активации\n",
    "class ModelSigmoid(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ModelSigmoid, self).__init__()\n",
    "        self.fc1 = nn.Linear(28 * 28, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, 10)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28 * 28)\n",
    "        x = self.sigmoid(self.fc1(x))\n",
    "        x = self.sigmoid(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# Функция обучения модели\n",
    "def train_model(model, train_loader, criterion, optimizer, num_epochs=5):\n",
    "    for epoch in range(num_epochs):\n",
    "        for images, labels in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "# Функция оценки модели\n",
    "def evaluate_model(model, test_loader):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    accuracy = correct / total\n",
    "    return accuracy"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-21T07:24:29.429157Z",
     "start_time": "2023-11-21T07:24:29.426140Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Задание 7.**\n",
    "Изменить функцию активации в нейронной сети (например, ReLU, сигмоида) и сравнить их влияние на качество распознавания."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with ReLU: 92.66%\n",
      "Accuracy with Sigmoid: 68.06%\n"
     ]
    }
   ],
   "source": [
    "# Определение критерия и оптимизатора\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Обучение и оценка первой модели с ReLU\n",
    "model_relu = ModelReLU()\n",
    "optimizer_relu = optim.SGD(model_relu.parameters(), lr=0.01)\n",
    "train_model(model_relu, train_loader, criterion, optimizer_relu)\n",
    "accuracy_relu = evaluate_model(model_relu, test_loader)\n",
    "\n",
    "# Обучение и оценка второй модели с сигмоидальной функцией активации\n",
    "model_sigmoid = ModelSigmoid()\n",
    "optimizer_sigmoid = optim.SGD(model_sigmoid.parameters(), lr=0.01)\n",
    "train_model(model_sigmoid, train_loader, criterion, optimizer_sigmoid)\n",
    "accuracy_sigmoid = evaluate_model(model_sigmoid, test_loader)\n",
    "\n",
    "# Сравнение результатов\n",
    "print(f'Accuracy with ReLU: {accuracy_relu * 100:.2f}%')\n",
    "print(f'Accuracy with Sigmoid: {accuracy_sigmoid * 100:.2f}%')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-21T07:25:05.325421Z",
     "start_time": "2023-11-21T07:24:29.429749Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Результаты отражают различия в производительности моделей с разными функциями активации. В данном случае, высокая точность с ReLU по сравнению с сигмоидальной функцией активации может быть объяснена следующими аспектами:\n",
    "\n",
    "1. **Преимущества ReLU:**\n",
    "   - ReLU (Rectified Linear Unit) обычно показывает хорошую производительность в нейронных сетях и может способствовать быстрой сходимости модели.\n",
    "   - ReLU не сталкивается с проблемой затухания градиентов, которая может возникнуть при использовании сигмоиды, особенно в глубоких сетях.\n",
    "\n",
    "2. **Сигмоидальная функция активации:**\n",
    "   - Сигмоидальная функция ограничивает значения в интервале (0, 1). Это может привести к проблеме затухания градиентов, особенно при обратном распространении ошибки через множество слоев.\n",
    "   - В данном случае, сигмоидальная функция активации, возможно, слишком сильно ограничивает выходные значения, затрудняя обучение модели."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
